{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=7, micro=9, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a65f97fcad91>:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# --- Uncomment to use only CPU (e.g. GPU memory is too small)\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"/usr/local/cuda-10.1/bin\")\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-10.1/lib64\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=True) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Old stuff:\n",
    "\n",
    "import pickle\n",
    "\n",
    "def process_sample(sample, sample_name):\n",
    "    force_power, force_angle = [float(x) for x in sample_name.split(\"_\")]\n",
    "    result = list()\n",
    "    for n in range(240):\n",
    "        if n == 5:\n",
    "            frame_power = force_power\n",
    "        else:\n",
    "            frame_power = 0\n",
    "        result.append(flatten_frame(sample[n], force_power, force_angle))\n",
    "    return result\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"samplesGeneration\", \"data\")\n",
    "models_dir = os.path.join(os.getcwd(), \"model\")\n",
    "\n",
    "data = list()\n",
    "files = os.listdir(data_dir)\n",
    "for num, fname in enumerate(files):\n",
    "    if not num % 10:\n",
    "        print(num, \"/\", len(files), end=\"\\r\")\n",
    "    with open(os.path.join(data_dir, fname), \"rb\") as f:\n",
    "        data.append(process_sample(pickle.load(f, encoding='latin1'), fname.rsplit(\".\", 1)[0]))\n",
    "\n",
    "x = list()\n",
    "y = list()\n",
    "for num, (values, sample) in enumerate(data.items()):\n",
    "    if not num % 10:\n",
    "        print(num, \"/\", len(files), end=\"\\r\")\n",
    "    force_power, force_angle = [float(x) for x in values.split(\"_\")]\n",
    "    for n in range(240 - 4):\n",
    "        if n == 5:\n",
    "            frame_power = force_power\n",
    "        else:\n",
    "            frame_power = 0\n",
    "        x.append(flatten_frame(sample[n], force_power, force_angle) +\n",
    "                 flatten_frame(sample[n+1], force_power, force_angle) + \n",
    "                 flatten_frame(sample[n+2], force_power, force_angle))\n",
    "        y.append(flatten_frame(sample[n+3], force_power, force_angle)[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 20:14:33,219: Logger started.\n"
     ]
    }
   ],
   "source": [
    "# reate logger - nocer formatting\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logging._warn_preinit_stderr = 0\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s: %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.handlers = [ch]\n",
    "logger.info(\"Logger started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import numpy as np\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    Save Numpy array to SqLite.\n",
    "    Source:\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    \"\"\" \n",
    "    Load Numpy array from Sqlite.\n",
    "    Source:\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "data_path = os.path.join(os.getcwd(), \"samplesGeneration\", \"prepared_data.bd\")\n",
    "db = sqlite3.connect(data_path, detect_types=sqlite3.PARSE_DECLTYPES, check_same_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# --- Uncomment to use only CPU (e.g. GPU memory is too small)\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"/usr/local/cuda-10.1/bin\")\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-10.1/lib64\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  1703921\n",
      "(array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  2.00099993e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  1.00000000e+00,  9.08880856e-01, -4.17055860e-01,\n",
      "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  4.00199986e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  1.00000000e+00, -7.58108174e-01,\n",
      "       -6.52128819e-01,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
      "        6.00299978e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
      "       -2.76533943e-01,  9.61004151e-01,  0.00000000e+00,  1.00000000e+00,\n",
      "        1.66296152e+00,  0.00000000e+00,  1.00000000e+00,  7.48810198e-05,\n",
      "        2.11998690e-06, -8.31112775e-05,  7.48810198e-05,  9.99999997e-01,\n",
      "        2.11998690e-06,  1.00000000e+00, -8.31112774e-05,  9.99999997e-01,\n",
      "       -5.57474632e-05,  1.99994695e+00,  2.09227568e-04, -5.57474632e-05,\n",
      "        9.99999998e-01,  9.09319501e-01, -4.16098599e-01,  2.09227567e-04,\n",
      "        9.99999978e-01,  2.46317504e-05,  3.99989533e+00,  7.34974719e-06,\n",
      "        2.46317504e-05,  1.00000000e+00, -7.56734077e-01, -6.53722829e-01,\n",
      "        7.34974719e-06,  1.00000000e+00,  2.51107471e-04,  5.99990797e+00,\n",
      "       -5.03815718e-05,  2.51107468e-04,  9.99999968e-01, -2.79503861e-01,\n",
      "        9.60144568e-01, -5.03815718e-05,  9.99999999e-01,  1.66296152e+00,\n",
      "        0.00000000e+00,  1.00000000e+00,  3.93934388e-05, -8.39499808e-06,\n",
      "        6.71610542e-06,  3.93934388e-05,  9.99999999e-01, -8.39499808e-06,\n",
      "        1.00000000e+00,  6.71610542e-06,  1.00000000e+00, -2.32565799e-04,\n",
      "        2.00000572e+00,  5.78839332e-04, -2.32565797e-04,  9.99999973e-01,\n",
      "        9.09295046e-01, -4.16152040e-01,  5.78839300e-04,  9.99999832e-01,\n",
      "       -2.95068021e-04,  4.00005817e+00,  4.21794801e-04, -2.95068017e-04,\n",
      "        9.99999956e-01, -7.56840519e-01, -6.53599593e-01,  4.21794788e-04,\n",
      "        9.99999911e-01,  4.47737373e-04,  6.00006962e+00,  1.41916447e-04,\n",
      "        4.47737358e-04,  9.99999900e-01, -2.79348652e-01,  9.60189737e-01,\n",
      "        1.41916447e-04,  9.99999990e-01,  1.66296152e+00,  0.00000000e+00,\n",
      "        1.00000000e+00]), array([ 6.52700874e-06, -2.15933669e-05,  2.04392869e-04,  6.52700874e-06,\n",
      "        1.00000000e+00, -2.15933669e-05,  1.00000000e+00,  2.04392867e-04,\n",
      "        9.99999979e-01, -3.31273332e-04,  1.99999964e+00,  8.21398280e-04,\n",
      "       -3.31273325e-04,  9.99999945e-01,  9.09297576e-01, -4.16146511e-01,\n",
      "        8.21398188e-04,  9.99999663e-01, -5.91558113e-04,  4.00001001e+00,\n",
      "        6.26989582e-04, -5.91558079e-04,  9.99999825e-01, -7.56809041e-01,\n",
      "       -6.53636043e-01,  6.26989541e-04,  9.99999803e-01,  2.43281276e-04,\n",
      "        6.00005198e+00,  1.37848227e-04,  2.43281274e-04,  9.99999970e-01,\n",
      "       -2.79365593e-01,  9.60184808e-01,  1.37848226e-04,  9.99999990e-01]))\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "db_cursor = db.cursor()\n",
    "sql_query = \"SELECT COALESCE(MAX(id)+1, 0) FROM data\"\n",
    "db_cursor.execute(sql_query)\n",
    "number_of_samples = db_cursor.fetchone()[0]\n",
    "print(\"number of samples: \", number_of_samples)\n",
    "\n",
    "sql_query = \"SELECT x, y FROM data WHERE id == 1\"\n",
    "db_cursor.execute(sql_query)\n",
    "print(db_cursor.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras from SQLite database'\n",
    "    def __init__(self, path, num_features, end_index=None, start_index=1, batch_size=25,\n",
    "                 shuffle=True, dim=(117, 1), dim_y=(114, 1), column=\"voxels\"):\n",
    "        'Initialization'\n",
    "        sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "        sqlite3.register_converter(\"array\", convert_array)\n",
    "        self.path = path\n",
    "        self.dim = dim\n",
    "        self.dim_y = dim_y\n",
    "        self.db = sqlite3.connect(self.path, detect_types=sqlite3.PARSE_DECLTYPES, check_same_thread=False)\n",
    "        self.db_cursor = self.db.cursor()\n",
    "        self.N = num_features\n",
    "        self.start_index = start_index\n",
    "        if end_index is None:\n",
    "            end_index =  num_features + start_index\n",
    "        self.end_index = end_index\n",
    "        self.column = column\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.shuffle = shuffle\n",
    "        self.sample_index = np.arange(self.start_index, self.end_index)\n",
    "        self.on_epoch_end()\n",
    "        self.db.close()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.N / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data - generates indexes of the batch'\n",
    "        # Generate indexes of the batch\n",
    "        samples_batch = np.arange((index) * self.batch_size, (index+1) * self.batch_size)\n",
    "\n",
    "        # Generate data\n",
    "        x, y = self.__data_generation(samples_batch)\n",
    "\n",
    "        return  x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.sample_index)\n",
    "\n",
    "    def __data_generation(self, samples_batch):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        x = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty(shape=(self.batch_size, *self.dim_y))\n",
    "        inds = self.sample_index[samples_batch]\n",
    "        sqlite3.register_adapter(np.ndarray, self.adapt_array)\n",
    "        sqlite3.register_converter(\"array\", self.convert_array)\n",
    "        db = sqlite3.connect(self.path, detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "        db_cursor = db.cursor()\n",
    "        sql_query = \"SELECT x, y FROM data WHERE id in ({index})\".\\\n",
    "            format(column=self.column, index=','.join(str(ind) for ind in inds))\n",
    "        db_cursor.execute(sql_query)\n",
    "        for i in range(self.batch_size):\n",
    "            line = db_cursor.fetchone()\n",
    "            x[i, :] = line[0].reshape(self.dim)\n",
    "            y[i] = line[1].reshape(self.dim_y)\n",
    "        # x.reshape(self.batch_size, *self.dim, 1)\n",
    "        y = y.reshape(self.batch_size, *self.dim_y)\n",
    "        return x, y\n",
    "    \n",
    "    def adapt_array(self, arr):\n",
    "        \"\"\"\n",
    "        Save Numpy array to SqLite.\n",
    "        Source:\n",
    "        http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "        \"\"\"\n",
    "        out = io.BytesIO()\n",
    "        np.save(out, arr)\n",
    "        out.seek(0)\n",
    "        return sqlite3.Binary(out.read())\n",
    "\n",
    "    def convert_array(self, text):\n",
    "        \"\"\" \n",
    "        Load Numpy array from Sqlite.\n",
    "        Source:\n",
    "        http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "        \"\"\"\n",
    "        out = io.BytesIO(text)\n",
    "        out.seek(0)\n",
    "        return np.load(out)\n",
    "    \n",
    "test_train_ratio = 0.1\n",
    "\n",
    "test_size = int(test_train_ratio * number_of_samples)\n",
    "training_generator = DataGenerator(data_path, num_features=number_of_samples - test_size, batch_size=64, dim=(117, 1), dim_y=(36, 1))\n",
    "validation_generator = DataGenerator(data_path, num_features=test_size, start_index=number_of_samples - test_size, batch_size=64, dim=(114, 1), dim_y=(36, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-03 20:14:57,454: start\n",
      "2020-12-03 20:14:57,456: Create model...\n",
      "2020-12-03 20:14:58,161: Fit model..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                3636      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 36, 1)             0         \n",
      "=================================================================\n",
      "Total params: 44,436\n",
      "Trainable params: 44,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 6082/23961 [======>.......................] - ETA: 22:14 - loss: 0.2383"
     ]
    }
   ],
   "source": [
    "# Try learning for all of verts:\n",
    "\n",
    "verts = range(14)\n",
    "pivot_vert = 3\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import LSTM\n",
    "from collections import deque\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "\n",
    "\n",
    "def create_and_train_network(generator, val_generator, epohs=100):\n",
    "    def create_model():\n",
    "        model = Sequential()\n",
    "        #model.add(LSTM(100, input_shape=generator.dim, return_sequences=True))\n",
    "        #model.add(Dropout(0.2))\n",
    "        model.add(LSTM(100, input_shape=generator.dim, return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "        #model.add(Flatten())\n",
    "        model.add(Dense(np.prod(generator.dim_y), activation='linear'))\n",
    "        model.add(Reshape((np.prod(generator.dim_y), 1)))\n",
    "        model.compile(loss='mae', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    logger.info(\"Create model...\")\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    logger.info(\"Fit model..\")\n",
    "    \n",
    "    network = model.fit_generator(training_generator, verbose=1, validation_data=validation_generator, \n",
    "                                              epochs=epohs, callbacks=[early_stopping])\n",
    "    logger.info(\"Summary\")\n",
    "    model.summary()\n",
    "    model.save(os.path.join(models_dir, \"model_all_points_{}\".format(sample_length)))\n",
    "\n",
    "\n",
    "logger.info(\"start\")\n",
    "create_and_train_network(training_generator, validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
