{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#time.sleep(60*60*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a65f97fcad91>:11: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# --- Uncomment to use only CPU (e.g. GPU memory is too small)\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"/usr/local/cuda-10.1/bin\")\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-10.1/lib64\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=True) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Old stuff:\n",
    "\n",
    "import pickle\n",
    "\n",
    "def process_sample(sample, sample_name):\n",
    "    force_power, force_angle = [float(x) for x in sample_name.split(\"_\")]\n",
    "    result = list()\n",
    "    for n in range(240):\n",
    "        if n == 5:\n",
    "            frame_power = force_power\n",
    "        else:\n",
    "            frame_power = 0\n",
    "        result.append(flatten_frame(sample[n], force_power, force_angle))\n",
    "    return result\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"samplesGeneration\", \"data\")\n",
    "models_dir = os.path.join(os.getcwd(), \"model\")\n",
    "\n",
    "data = list()\n",
    "files = os.listdir(data_dir)\n",
    "for num, fname in enumerate(files):\n",
    "    if not num % 10:\n",
    "        print(num, \"/\", len(files), end=\"\\r\")\n",
    "    with open(os.path.join(data_dir, fname), \"rb\") as f:\n",
    "        data.append(process_sample(pickle.load(f, encoding='latin1'), fname.rsplit(\".\", 1)[0]))\n",
    "\n",
    "x = list()\n",
    "y = list()\n",
    "for num, (values, sample) in enumerate(data.items()):\n",
    "    if not num % 10:\n",
    "        print(num, \"/\", len(files), end=\"\\r\")\n",
    "    force_power, force_angle = [float(x) for x in values.split(\"_\")]\n",
    "    for n in range(240 - 4):\n",
    "        if n == 5:\n",
    "            frame_power = force_power\n",
    "        else:\n",
    "            frame_power = 0\n",
    "        x.append(flatten_frame(sample[n], force_power, force_angle) +\n",
    "                 flatten_frame(sample[n+1], force_power, force_angle) + \n",
    "                 flatten_frame(sample[n+2], force_power, force_angle))\n",
    "        y.append(flatten_frame(sample[n+3], force_power, force_angle)[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 11:27:20,805: Logger started.\n"
     ]
    }
   ],
   "source": [
    "# reate logger - nocer formatting\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logging._warn_preinit_stderr = 0\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s: %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.handlers = [ch]\n",
    "logger.info(\"Logger started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import numpy as np\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    Save Numpy array to SqLite.\n",
    "    Source:\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    \"\"\" \n",
    "    Load Numpy array from Sqlite.\n",
    "    Source:\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "data_path = os.path.join(os.getcwd(), \"samplesGeneration\", \"prepared_data.bd\")\n",
    "source = sqlite3.connect(data_path, detect_types=sqlite3.PARSE_DECLTYPES, check_same_thread=False)\n",
    "db = sqlite3.connect(':memory:')\n",
    "source.backup(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# --- Uncomment to use only CPU (e.g. GPU memory is too small)\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"/usr/local/cuda-10.1/bin\")\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-10.1/lib64\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  1703921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x27535de73b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "db_cursor = db.cursor()\n",
    "sql_query = \"SELECT COALESCE(MAX(id)+1, 0) FROM data\"\n",
    "db_cursor.execute(sql_query)\n",
    "number_of_samples = db_cursor.fetchone()[0]\n",
    "print(\"number of samples: \", number_of_samples)\n",
    "\n",
    "sql_query = \"SELECT x, y FROM data WHERE id == 1\"\n",
    "db_cursor.execute(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras from SQLite database'\n",
    "    def __init__(self, path, indexes=None, batch_size=25,\n",
    "                 shuffle=True, dim=(3, 39, 1), dim_y=(36, 1), column=\"voxels\"):\n",
    "        'Initialization'\n",
    "        if indexes is None:\n",
    "            raise Exception(\"Indexes need to be provided!\")\n",
    "        sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "        sqlite3.register_converter(\"array\", convert_array)\n",
    "        self.path = path\n",
    "        self.dim = dim\n",
    "        self.dim_y = dim_y\n",
    "        self.db = sqlite3.connect(self.path, detect_types=sqlite3.PARSE_DECLTYPES, check_same_thread=False)\n",
    "        self.db_cursor = self.db.cursor()\n",
    "        self.N = len(indexes) - 1\n",
    "        self.sample_index = indexes\n",
    "        self.column = column\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.db.close()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.N / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data - generates indexes of the batch'\n",
    "        # Generate indexes of the batch\n",
    "        samples_batch = np.arange((index) * self.batch_size, (index+1) * self.batch_size)\n",
    "\n",
    "        # Generate data\n",
    "        while True:\n",
    "            try:\n",
    "                x, y = self.__data_generation(samples_batch)\n",
    "                break\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        return  x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.sample_index)\n",
    "\n",
    "    def __data_generation(self, samples_batch):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        x = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty(shape=(self.batch_size, *self.dim_y))\n",
    "        inds = self.sample_index[samples_batch]\n",
    "        sqlite3.register_adapter(np.ndarray, self.adapt_array)\n",
    "        sqlite3.register_converter(\"array\", self.convert_array)\n",
    "        db = sqlite3.connect(self.path, detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "        db_cursor = db.cursor()\n",
    "        sql_query = \"SELECT x, y FROM data WHERE id in ({index})\".\\\n",
    "            format(column=self.column, index=','.join(str(ind) for ind in inds))\n",
    "        db_cursor.execute(sql_query)\n",
    "        try:\n",
    "            for i, line in zip(range(self.batch_size), db_cursor.fetchall()):\n",
    "                if line is None:\n",
    "                    x[i, :] = x[i - 1, :]\n",
    "                    y[i] = y[i - 1]\n",
    "                    continue # Bad, temporary solution\n",
    "                x[i, :] = np.array(np.array_split(line[0].reshape(self.dim), 3)).reshape(self.dim)\n",
    "                y[i] = line[1].reshape(self.dim_y)\n",
    "        except TypeError as e:\n",
    "            print(sql_query)\n",
    "            raise e\n",
    "        # x.reshape(self.batch_size, *self.dim, 1)\n",
    "        y = y.reshape(self.batch_size, *self.dim_y)\n",
    "        return x, y\n",
    "    \n",
    "    def adapt_array(self, arr):\n",
    "        \"\"\"\n",
    "        Save Numpy array to SqLite.\n",
    "        Source:\n",
    "        http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "        \"\"\"\n",
    "        out = io.BytesIO()\n",
    "        np.save(out, arr)\n",
    "        out.seek(0)\n",
    "        return sqlite3.Binary(out.read())\n",
    "\n",
    "    def convert_array(self, text):\n",
    "        \"\"\" \n",
    "        Load Numpy array from Sqlite.\n",
    "        Source:\n",
    "        http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "        \"\"\"\n",
    "        out = io.BytesIO(text)\n",
    "        out.seek(0)\n",
    "        return np.load(out)\n",
    "    \n",
    "test_train_ratio = 0.1\n",
    "\n",
    "test_size = int(test_train_ratio * number_of_samples)\n",
    "\n",
    "indexes = np.arange(0, number_of_samples - 1)\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, val_indexes = indexes[:-test_size], indexes[test_size:]\n",
    "\n",
    "training_generator = DataGenerator(data_path, indexes=train_indexes, batch_size=32, dim=(3, 39), dim_y=(1, 36))\n",
    "validation_generator = DataGenerator(data_path, indexes=val_indexes, batch_size=32, dim=(3, 39), dim_y=(1, 36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "best_model_file = \"model.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', mode='min',verbose=1, save_best_only=True)\n",
    "\n",
    "models_dir = os.path.join(os.getcwd(), \"samplesGeneration\", \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 11:27:26,607: start\n",
      "2020-12-06 11:27:26,608: Create model...\n",
      "2020-12-06 11:27:27,258: Fit model..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 36)                10944     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 36, 1)             0         \n",
      "=================================================================\n",
      "Total params: 10,944\n",
      "Trainable params: 10,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-9-ea37ca481ab9>:41: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 11:27:27,258: From <ipython-input-9-ea37ca481ab9>:41: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 11:27:27,279: sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 11:27:27,322: sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 47922 steps, validate for 47922 steps\n",
      "Epoch 1/10\n",
      "47919/47922 [============================>.] - ETA: 0s - loss: 9.1444e-04\n",
      "Epoch 00001: val_loss improved from inf to 0.00087, saving model to model.h5\n",
      "47922/47922 [==============================] - 1811s 38ms/step - loss: 9.1445e-04 - val_loss: 8.6744e-04\n",
      "Epoch 2/10\n",
      "47920/47922 [============================>.] - ETA: 0s - loss: 8.6831e-04\n",
      "Epoch 00002: val_loss improved from 0.00087 to 0.00087, saving model to model.h5\n",
      "47922/47922 [==============================] - 1798s 38ms/step - loss: 8.6829e-04 - val_loss: 8.6608e-04\n",
      "Epoch 3/10\n",
      "47921/47922 [============================>.] - ETA: 0s - loss: 8.6822e-04\n",
      "Epoch 00003: val_loss improved from 0.00087 to 0.00087, saving model to model.h5\n",
      "47922/47922 [==============================] - 1792s 37ms/step - loss: 8.6820e-04 - val_loss: 8.6572e-04\n",
      "Epoch 4/10\n",
      "47920/47922 [============================>.] - ETA: 0s - loss: 8.6823e-04\n",
      "Epoch 00004: val_loss did not improve from 0.00087\n",
      "47922/47922 [==============================] - 1792s 37ms/step - loss: 8.6820e-04 - val_loss: 8.6629e-04\n",
      "Epoch 5/10\n",
      "47920/47922 [============================>.] - ETA: 0s - loss: 8.6815e-04\n",
      "Epoch 00005: val_loss improved from 0.00087 to 0.00087, saving model to model.h5\n",
      "47922/47922 [==============================] - 1800s 38ms/step - loss: 8.6814e-04 - val_loss: 8.6570e-04\n",
      "Epoch 6/10\n",
      "47920/47922 [============================>.] - ETA: 0s - loss: 8.6814e-04\n",
      "Epoch 00006: val_loss did not improve from 0.00087\n",
      "47922/47922 [==============================] - 1793s 37ms/step - loss: 8.6815e-04 - val_loss: 8.6582e-04\n",
      "Epoch 7/10\n",
      "47919/47922 [============================>.] - ETA: 0s - loss: 8.6815e-04\n",
      "Epoch 00007: val_loss did not improve from 0.00087\n",
      "47922/47922 [==============================] - 1788s 37ms/step - loss: 8.6816e-04 - val_loss: 8.6589e-04\n",
      "Epoch 8/10\n",
      "47920/47922 [============================>.] - ETA: 0s - loss: 8.6814e-04\n",
      "Epoch 00008: val_loss improved from 0.00087 to 0.00087, saving model to model.h5\n",
      "47922/47922 [==============================] - 1788s 37ms/step - loss: 8.6812e-04 - val_loss: 8.6553e-04\n",
      "Epoch 9/10\n",
      "47919/47922 [============================>.] - ETA: 0s - loss: 8.6810e-04\n",
      "Epoch 00009: val_loss did not improve from 0.00087\n",
      "47922/47922 [==============================] - 1791s 37ms/step - loss: 8.6808e-04 - val_loss: 8.6624e-04\n",
      "Epoch 10/10\n",
      "47921/47922 [============================>.] - ETA: 0s - loss: 8.6809e-04\n",
      "Epoch 00010: val_loss did not improve from 0.00087\n",
      "47922/47922 [==============================] - 1794s 37ms/step - loss: 8.6810e-04 - val_loss: 8.6573e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-06 16:26:36,036: Summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 36)                10944     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 36, 1)             0         \n",
      "=================================================================\n",
      "Total params: 10,944\n",
      "Trainable params: 10,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ea37ca481ab9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_and_train_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-ea37ca481ab9>\u001b[0m in \u001b[0;36mcreate_and_train_network\u001b[1;34m(generator, val_generator, epohs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Summary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_all_points_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_length' is not defined"
     ]
    }
   ],
   "source": [
    "# Try learning for all of verts:\n",
    "\n",
    "verts = range(14)\n",
    "pivot_vert = 3\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from collections import deque\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "\n",
    "\n",
    "models_dir = os.path.join(os.getcwd(), \"samplesGeneration\", \"logs\", \"model_{}\".format(time.time()))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def create_and_train_network(generator, val_generator, epohs=10):\n",
    "    log_dir = os.path.join(os.getcwd(), \"samplesGeneration\", \"logs\", \"model_{}\".format(time.time()))\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    def create_model():\n",
    "        model = Sequential()\n",
    "        #model.add(LSTM(512, input_shape=generator.dim, return_sequences=True))\n",
    "        #model.add(Dropout(0.2))\n",
    "        model.add(LSTM(np.prod(generator.dim_y), input_shape=generator.dim, return_sequences=False, dropout=0.2))\n",
    "        #model.add(Flatten())\n",
    "        #model.add(Dense(256, activation='linear'))\n",
    "        #model.add(Dense(np.prod(generator.dim_y), activation='linear'))\n",
    "        model.add(Reshape((np.prod(generator.dim_y), 1)))\n",
    "        model.compile(loss=\"mse\", optimizer='rmsprop')\n",
    "        return model\n",
    "\n",
    "    logger.info(\"Create model...\")\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    logger.info(\"Fit model..\")\n",
    "    network = model.fit_generator(training_generator, verbose=1, validation_data=validation_generator, \n",
    "                                  epochs=epohs, callbacks=[early_stopping, best_model, tensorboard_callback])\n",
    "    logger.info(\"Summary\")\n",
    "    model.summary()\n",
    "    model.save(os.path.join(models_dir, \"model_all_points_{}\".format(sample_length)))\n",
    "    return network\n",
    "\n",
    "\n",
    "logger.info(\"start\")\n",
    "network = create_and_train_network(training_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "model = tf.keras.models.load_model(best_model_file)\n",
    "\n",
    "tf.saved_model.save(model, \"model\\\\saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "db = sqlite3.connect(data_path, detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "db_cursor = db.cursor()\n",
    "sql_query = \"SELECT x, y FROM data WHERE id == 1\"\n",
    "db_cursor.execute(sql_query)\n",
    "data = db_cursor.fetchone()[0]\n",
    "print(data.shape)\n",
    "predicted= list()\n",
    "frames = np.array(np.array_split(data, 3))\n",
    "for f in frames:\n",
    "    predicted.append(f)\n",
    "\n",
    "for n in range(240):\n",
    "    _in  = np.concatenate((predicted[-3], predicted[-2], predicted[-1])).reshape(116, 1)\n",
    "    pred = model.predict(_in)\n",
    "    p = (n ==5) *10\n",
    "    np.append(pred, p)\n",
    "    np.append(pred, data[-2])\n",
    "    np.append(pred, data[-1])\n",
    "    print(pred.shape)\n",
    "    predicted.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d', xlim=(-2,2),ylim=(-2,2), zlim=(0, 10))\n",
    "\n",
    "xs = list()\n",
    "ys = list()\n",
    "zs = list()\n",
    "sizes = list()\n",
    "sample_to_plot = data[600]\n",
    "for num, f in enumerate(sample_to_plot):\n",
    "    for i in range(4):\n",
    "        v = [f[9*i], f[9*i + 1], f[9*i + 2]]\n",
    "        # print(v)\n",
    "        xs.append(v[0])\n",
    "        ys.append(v[2])\n",
    "        zs.append(v[1])\n",
    "        sizes.append([(len(sample_to_plot) - float(num))/len(sample_to_plot), 0, 0])\n",
    "ax.scatter(xs, ys, zs, c=sizes)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
